{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PV4luiywG-KT"
   },
   "source": [
    "# Importing Basic Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EiwosQqIG-KV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "0ie4qAFkG-KW",
    "outputId": "b9c0e695-4184-472c-9250-5c9884d65404"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PU4epGWEG-KX",
    "outputId": "f66fe9eb-7f63-43d7-f9a8-d5d16aff8652"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "JKjCbfvjG-KX",
    "outputId": "0890bfcc-2f42-4625-be07-b3de0d6fe43b"
   },
   "outputs": [],
   "source": [
    "# removing the unnamed: 0 col\n",
    "\n",
    "df = df[['Company', 'TypeName', 'Inches', 'ScreenResolution',\n",
    "       'Cpu', 'Ram', 'Memory', 'Gpu', 'OpSys', 'Weight', 'Price']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2zKt1qZG-KX",
    "outputId": "ecdd49e6-54ff-4fb3-9446-b76387122264"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UmD8UhvG-KX",
    "outputId": "ecaa64b9-7499-41e7-9a17-83100129e053"
   },
   "outputs": [],
   "source": [
    "# checking for duplicated rows\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25RByYvhG-KX",
    "outputId": "cea065c7-521f-4561-ad25-6fdff7abe2e9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Ram' and 'Weight' to numerical values\n",
    "laptop_data['Ram'] = laptop_data['Ram'].str.replace('GB', '').astype(int)\n",
    "laptop_data['Weight'] = laptop_data['Weight'].str.replace('kg', '').astype(float)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = laptop_data.isnull().sum()\n",
    "\n",
    "# Updated dataset and missing values info\n",
    "updated_dataset_info = {\n",
    "    \"First Five Rows\": laptop_data.head(),\n",
    "    \"Missing Values\": missing_values\n",
    "}\n",
    "\n",
    "updated_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Creating subplots for various visualizations\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Distribution of RAM\n",
    "sns.histplot(laptop_data['Ram'], kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribution of RAM')\n",
    "\n",
    "# Distribution of Inches (Screen Size)\n",
    "sns.histplot(laptop_data['Inches'], kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Distribution of Screen Size (Inches)')\n",
    "\n",
    "# Distribution of Weight\n",
    "sns.histplot(laptop_data['Weight'], kde=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribution of Weight')\n",
    "\n",
    "# Distribution of Price\n",
    "sns.histplot(laptop_data['Price'], kde=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribution of Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting up the figure for multiple plots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 15))\n",
    "\n",
    "# Plotting count distribution of categorical variables\n",
    "sns.countplot(y='Company', data=laptop_data, order = laptop_data['Company'].value_counts().index, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Count of Laptops by Company')\n",
    "\n",
    "sns.countplot(y='TypeName', data=laptop_data, order = laptop_data['TypeName'].value_counts().index, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Count of Laptops by TypeName')\n",
    "\n",
    "sns.countplot(y='OpSys', data=laptop_data, order = laptop_data['OpSys'].value_counts().index, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Count of Laptops by Operating System')\n",
    "\n",
    "# Due to a large number of unique values, we'll limit the CPU and GPU plots to the top 10\n",
    "top_cpus = laptop_data['Cpu'].value_counts().index[:10]\n",
    "sns.countplot(y='Cpu', data=laptop_data[laptop_data['Cpu'].isin(top_cpus)], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Top 10 CPUs in Laptops')\n",
    "\n",
    "top_gpus = laptop_data['Gpu'].value_counts().index[:10]\n",
    "sns.countplot(y='Gpu', data=laptop_data[laptop_data['Gpu'].isin(top_gpus)], ax=axes[2, 0])\n",
    "axes[2, 0].set_title('Top 10 GPUs in Laptops')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Due to the complexity and variety in ScreenResolution, we'll need a different approach to analyze it effectively.\n",
    "# Let's display the top 10 most common screen resolutions.\n",
    "top_screen_resolutions = laptop_data['ScreenResolution'].value_counts().head(10)\n",
    "top_screen_resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# 1. Creating the Touchscreen feature\n",
    "laptop_data['Touchscreen'] = laptop_data['ScreenResolution'].apply(lambda x: 1 if 'Touchscreen' in x else 0)\n",
    "\n",
    "# 2. Creating the IPS feature\n",
    "laptop_data['IPS'] = laptop_data['ScreenResolution'].apply(lambda x: 1 if 'IPS' in x else 0)\n",
    "\n",
    "# 3. Extracting X and Y Resolution\n",
    "# First, we extract the resolution part from the ScreenResolution column\n",
    "resolution = laptop_data['ScreenResolution'].str.extract('(\\d+)x(\\d+)')\n",
    "# Then we create new columns for X_Res and Y_Res\n",
    "laptop_data['X_Res'] = resolution[0].astype(int)\n",
    "laptop_data['Y_Res'] = resolution[1].astype(int)\n",
    "\n",
    "# Displaying the first few rows of the updated dataset\n",
    "laptop_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = laptop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IPS'] = df['ScreenResolution'].apply(\n",
    "    lambda element:1 if \"IPS\" in element else 0\n",
    ")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate PPI\n",
    "def calculate_ppi(row):\n",
    "    return np.sqrt(row['X_Res']**2 + row['Y_Res']**2) / row['Inches']\n",
    "\n",
    "# Creating the PPI column\n",
    "laptop_data['PPI'] = laptop_data.apply(calculate_ppi, axis=1)\n",
    "\n",
    "# Dropping the X_Res and Y_Res columns\n",
    "laptop_data.drop(columns=['X_Res', 'Y_Res'], inplace=True)\n",
    "\n",
    "# Checking the first few rows of the updated dataset\n",
    "laptop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Selecting numeric features\n",
    "numeric_data = laptop_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculating the correlation matrix\n",
    "corr_matrix = numeric_data.corr()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = numeric_data.corr()['Price']\n",
    "corr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the column names of the dataset\n",
    "column_names = laptop_data.columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting CPU name\n",
    "laptop_data['CPU_Name'] = laptop_data['Cpu'].str.extract(r'(\\bIntel\\b.*?|\\bAMD\\b.*?)\\s+\\d')\n",
    "\n",
    "# Checking the first few entries of the new column\n",
    "print(laptop_data['CPU_Name'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original Cpu column\n",
    "laptop_data.drop('Cpu', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert storage size to integer in GB\n",
    "def size_to_gb(size_str):\n",
    "    size_match = re.search(r'(\\d+\\.?\\d*)', size_str)\n",
    "    if size_match:\n",
    "        size = float(size_match.group(1))\n",
    "        if 'TB' in size_str:\n",
    "            return int(size * 1024)  # Convert TB to GB\n",
    "        return int(size)\n",
    "    return 0\n",
    "\n",
    "# Function to update the storage columns\n",
    "def update_storage(row):\n",
    "    storage_entries = row['Memory'].split(\"+\")\n",
    "    for entry in storage_entries:\n",
    "        if 'HDD' in entry:\n",
    "            row['HDD'] += size_to_gb(entry)\n",
    "        elif 'SSD' in entry:\n",
    "            row['SSD'] += size_to_gb(entry)\n",
    "        elif 'Flash Storage' in entry:\n",
    "            row['Flash Storage'] += size_to_gb(entry)\n",
    "        elif 'Hybrid' in entry:\n",
    "            row['Hybrid'] += size_to_gb(entry)\n",
    "    return row\n",
    "\n",
    "# Initialize new columns for storage types\n",
    "laptop_data['HDD'] = 0\n",
    "laptop_data['SSD'] = 0\n",
    "laptop_data['Flash Storage'] = 0\n",
    "laptop_data['Hybrid'] = 0\n",
    "\n",
    "# Apply the function to each row\n",
    "laptop_data = laptop_data.apply(update_storage, axis=1)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "laptop_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Selecting numeric features\n",
    "numeric_data = laptop_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculating the correlation matrix\n",
    "corr_matrix = numeric_data.corr()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = numeric_data.corr()['Price']\n",
    "corr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize the operating system\n",
    "def categorize_os(os_str):\n",
    "    if 'Windows' in os_str:\n",
    "        return 'Windows'\n",
    "    elif 'Linux' in os_str or 'Ubuntu' in os_str:\n",
    "        return 'Linux'\n",
    "    elif 'macOS' in os_str or 'Mac OS' in os_str:\n",
    "        return 'Apple'\n",
    "    else:\n",
    "        return 'Other OS'\n",
    "\n",
    "# Creating the new column\n",
    "laptop_data['OpSys_Simple'] = laptop_data['OpSys'].apply(categorize_os)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(laptop_data[['OpSys', 'OpSys_Simple']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the specified columns\n",
    "columns_to_drop = ['ScreenResolution', 'Memory', 'Gpu', 'Flash Storage', 'Hybrid', 'Memory Size']\n",
    "laptop_data.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# Displaying the first few rows of the updated dataset\n",
    "laptop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Selecting numeric features\n",
    "numeric_data = laptop_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculating the correlation matrix\n",
    "corr_matrix = numeric_data.corr()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = numeric_data.corr()['Price']\n",
    "corr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Define target and features\n",
    "X = laptop_data.drop('Price', axis=1)\n",
    "y = np.log(laptop_data['Price']) # Log normalization of the Price\n",
    "\n",
    "# Handling categorical variables\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluating Linear Regression\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "print(\"Linear Regression MAE:\", lr_mae)\n",
    "print(\"Linear Regression R²:\", lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluating Ridge Regression\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_predictions)\n",
    "ridge_r2 = r2_score(y_test, ridge_predictions)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae)\n",
    "print(\"Ridge Regression R²:\", ridge_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Lasso\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluating Lasso\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_predictions)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "print(\"Lasso MAE:\", lasso_mae)\n",
    "print(\"Lasso R²:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluating Decision Tree\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "print(\"Decision Tree MAE:\", dt_mae)\n",
    "print(\"Decision Tree R²:\", dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating Random Forest\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "print(\"Random Forest MAE:\", rf_mae)\n",
    "print(\"Random Forest R²:\", rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Adjusted parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 'log2'],  # Replaced 'auto' with 'sqrt'\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n",
    "\n",
    "# Plotting for Decision Tree (example)\n",
    "decision_tree = models['Decision Tree']\n",
    "path = decision_tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "# Plotting the ccp_alpha vs accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    dt = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_scores.append(dt.score(X_train, y_train))\n",
    "    test_scores.append(dt.score(X_test, y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle=\"steps-post\")\n",
    "plt.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle=\"steps-post\")\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs alpha for training and testing sets')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(decision_tree, filled=True, max_depth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the best Random Forest model\n",
    "laptop_data['Predicted Price'] = np.exp(best_rf_model.predict(X_transformed)) # Inverse of log transformation\n",
    "\n",
    "# Plotting actual vs predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(laptop_data['Price'], laptop_data['Predicted Price'], alpha=0.5)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual Price vs Predicted Price')\n",
    "plt.plot([laptop_data['Price'].min(), laptop_data['Price'].max()], [laptop_data['Price'].min(), laptop_data['Price'].max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the density plot for actual and predicted prices using updated seaborn functions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(laptop_data['Price'], fill=True, label='Actual Price')\n",
    "sns.kdeplot(laptop_data['Predicted Price'], fill=True, label='Predicted Price')\n",
    "\n",
    "plt.title('Density Plot of Actual Price vs Predicted Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming X_train is your csr_matrix\n",
    "if isinstance(X_train, csr_matrix):\n",
    "    X_train_df = pd.DataFrame(X_train.toarray())\n",
    "else:\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "X_train_df.to_csv('train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('train_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).to_csv('train_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $End$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
